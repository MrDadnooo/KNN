{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment - detekcia s použitím informácie o vzdialenosti"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ba379e9575a5e58"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-10T16:12:16.599658Z",
     "start_time": "2024-05-10T16:11:50.713878400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the data manager\n",
      "Data manager initialization finished\n"
     ]
    }
   ],
   "source": [
    "import dataset, model, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_set = dataset.load_data_set('../res/cache/datasets/dataset_1000')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T16:32:34.920213600Z",
     "start_time": "2024-05-10T16:32:27.712388400Z"
    }
   },
   "id": "694d89869ae37b77"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/991 [00:00<?, ?it/s]C:\\Users\\H492635\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      " 53%|█████▎    | 521/991 [05:47<05:13,  1.50it/s]  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m clip_distances \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data_point \u001B[38;5;129;01min\u001B[39;00m tqdm(data_set):\n\u001B[1;32m----> 5\u001B[0m     clip_distances\u001B[38;5;241m.\u001B[39mappend(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_clip_lines_dst\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_point\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\scripts\\model.py:52\u001B[0m, in \u001B[0;36mcompute_clip_lines_dst\u001B[1;34m(data_point)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_clip_lines_dst\u001B[39m(data_point: dataset\u001B[38;5;241m.\u001B[39mDataPoint) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[ImageAnnotation, \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mtuple\u001B[39m[TextLine, \u001B[38;5;28mfloat\u001B[39m]]]:\n\u001B[0;32m     51\u001B[0m     text: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m [line\u001B[38;5;241m.\u001B[39men_text \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m data_point\u001B[38;5;241m.\u001B[39mtext_lines]\n\u001B[1;32m---> 52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m__compute_clip_distances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_lines\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\scripts\\model.py:29\u001B[0m, in \u001B[0;36m__compute_clip_distances\u001B[1;34m(data_point, text, point_entities)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__compute_clip_distances\u001B[39m(data_point: dataset\u001B[38;5;241m.\u001B[39mDataPoint, text: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m], point_entities: \u001B[38;5;28mlist\u001B[39m[Any]) \\\n\u001B[0;32m     28\u001B[0m         \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[ImageAnnotation, \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mtuple\u001B[39m[Any, \u001B[38;5;28mfloat\u001B[39m]]]:\n\u001B[1;32m---> 29\u001B[0m     tokenized_text \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     30\u001B[0m     result: \u001B[38;5;28mdict\u001B[39m[ImageAnnotation, \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mtuple\u001B[39m[Any, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m image_ann \u001B[38;5;129;01min\u001B[39;00m data_point\u001B[38;5;241m.\u001B[39mimg_annotations:\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\venv\\Lib\\site-packages\\open_clip\\tokenizer.py:250\u001B[0m, in \u001B[0;36mSimpleTokenizer.__call__\u001B[1;34m(self, texts, context_length)\u001B[0m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;66;03m# use reduction strategy for tokenize if set, otherwise default to truncation below\u001B[39;00m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction_fn(\n\u001B[0;32m    243\u001B[0m         texts,\n\u001B[0;32m    244\u001B[0m         context_length\u001B[38;5;241m=\u001B[39mcontext_length,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    247\u001B[0m         encode_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode,\n\u001B[0;32m    248\u001B[0m     )\n\u001B[1;32m--> 250\u001B[0m all_tokens \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msot_token_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meot_token_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    251\u001B[0m result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(all_tokens), context_length, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, tokens \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(all_tokens):\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\venv\\Lib\\site-packages\\open_clip\\tokenizer.py:250\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;66;03m# use reduction strategy for tokenize if set, otherwise default to truncation below\u001B[39;00m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction_fn(\n\u001B[0;32m    243\u001B[0m         texts,\n\u001B[0;32m    244\u001B[0m         context_length\u001B[38;5;241m=\u001B[39mcontext_length,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    247\u001B[0m         encode_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode,\n\u001B[0;32m    248\u001B[0m     )\n\u001B[1;32m--> 250\u001B[0m all_tokens \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msot_token_id] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meot_token_id] \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts]\n\u001B[0;32m    251\u001B[0m result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(all_tokens), context_length, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, tokens \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(all_tokens):\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\venv\\Lib\\site-packages\\open_clip\\tokenizer.py:209\u001B[0m, in \u001B[0;36mSimpleTokenizer.encode\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[0;32m    208\u001B[0m     bpe_tokens \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 209\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclean_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m re\u001B[38;5;241m.\u001B[39mfindall(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpat, text):\n\u001B[0;32m    211\u001B[0m         token \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbyte_encoder[b] \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m token\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\venv\\Lib\\site-packages\\open_clip\\tokenizer.py:85\u001B[0m, in \u001B[0;36m_clean_lower\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_clean_lower\u001B[39m(x):\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# basic, remove whitespace, lower case\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m whitespace_clean(\u001B[43mbasic_clean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mlower()\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\venv\\Lib\\site-packages\\open_clip\\tokenizer.py:67\u001B[0m, in \u001B[0;36mbasic_clean\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbasic_clean\u001B[39m(text):\n\u001B[1;32m---> 67\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[43mftfy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfix_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m     text \u001B[38;5;241m=\u001B[39m html\u001B[38;5;241m.\u001B[39munescape(html\u001B[38;5;241m.\u001B[39munescape(text))\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m text\u001B[38;5;241m.\u001B[39mstrip()\n",
      "File \u001B[1;32m~\\PycharmProjects\\KNN\\venv\\Lib\\site-packages\\ftfy\\__init__.py:350\u001B[0m, in \u001B[0;36mfix_text\u001B[1;34m(text, config, **kwargs)\u001B[0m\n\u001B[0;32m    348\u001B[0m out \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    349\u001B[0m pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 350\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m pos \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(text):\n\u001B[0;32m    351\u001B[0m     textbreak \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, pos) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m textbreak \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "clip_distances = []\n",
    "for data_point in tqdm(data_set):\n",
    "    clip_distances.append(model.compute_clip_lines_dst(data_point))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T16:40:19.829256100Z",
     "start_time": "2024-05-10T16:34:31.807527700Z"
    }
   },
   "id": "28a6cb3fd97ba9b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d861ec6e655ce66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
